---
id: 2
img: 2.png
title: "Prometheus and high memory consumption"
desc: "Ways to trim down Prometheus memory consumption"
tags:
  - sre
  - prometheus
  - memory
date: '2024-10-09T04:00:00.000Z'
---

Recently, I came upon two tools that help us analyze metrics and labels<sup>[1]</sup><sup>[2]</sup><sup>[3]</sup>. This analysis is especially useful when trying to reduce:
* metrics
* memory consumption

## Cardinality Analysis using `Promtool`

**Copy over data**
Create a new pod, with a new volume and the Prometheus data volume attached.

Copy over the data from the Prometheus volume to your new volume.
```bash
rsync -az --no-i-r --info=progress2 --no-i-r <PROD-VOLUME> <NEW-ANALYSIS-VOLUME>
```

**Setup promtool**

```bash
wget https://github.com/prometheus/prometheus/releases/download/v2.55.0/prometheus-2.55.0.linux-amd64.tar.gz
tar -xzf prometheus-2.55.0.linux-amd64.tar.gz
cd prometheus-2.55.0.linux-amd64
```

**Analysis**

Run the analysis using `promtool` and the new data directory:
```bash
./promtool tsdb analyze <PROMETHEUS-DATA-DIR> > tsdb-analysis.txt
```

This provides some useful information:
* Label names most involved in churning
* Most common label pairs
* Label names with highest cumulative label value length
* Highest cardinality labels

which helps us decide which label pairs or labels to drop - assuming the time series is still unique afterwards.

For my case, the `id` label was an obvious culprit that had a high cardinality and was not being used anywhere in alerting or in Grafana.

This is what the label drop looks like in the Prometheus helm chart values:
```diff
    cAdvisorMetricRelabelings:
+     # Drop id label from all metrics
+     - action: labeldrop
+       regex: 'id'
```

## Metrics Analysis using `Mimirtool`

**Install mimirtool**

For macOS, there's `brew`, for other package managers, see [mimirtool installation](https://grafana.com/docs/mimir/latest/manage/tools/mimirtool/#installation)
```bash
brew install mimirtool
```

**Grafana analysis**
```bash
mimirtool analyze grafana --address=https://<GRAFANA_ADDRESS> --key <GRAFANA_TOKEN>
```
This should output a file named `metrics-in-grafana.json`. We'll need it later.

**Prometheus rules analysis**
```bash
# Fetch all rules
kubectl exec -it <PROMETHEUS_POD> -n monitoring \
  -- sh -c 'for i in `find /etc/prometheus/rules/ -type f` ; do cat $i ; done' \
  | sed -e 's/groups://g' -e '1s/^/groups:/' > my-prom-rules.yaml

mimirtool analyze rule-file my-prom-rules.yaml
```
This will output a a file named `metrics-in-ruler.json`. Will need this in the next command.


**Metrics analysis**
Run `mimirtool` against Prometheus using the file from the previous commands.
```bash
mimirtool analyze prometheus \
    --grafana-metrics-file metrics-in-grafana.json \
    --ruler-metrics-file metrics-in-ruler.json \
    --address <PROMETHEUS_ADDRESS>
```
This should output a file named `prometheus-metrics.json`.

Finally, we can retrieve a list of unused metrics using `jq`<sup>[4]<sup>:
```bash
jq -r ".additional_metric_counts[].metric" prometheus-metrics.json | sort > unused-metrics.txt
```

It's important to note here that these were just the metrics used in Grafana. If the Prometheus metrics are being used elsewhere like [Keda](https://keda.sh/), those will also need to be taken into account by adding them into one of the following files from above.

## References
1. https://grafana.com/blog/2022/10/20/how-to-manage-high-cardinality-metrics-in-prometheus-and-kubernetes/
2. https://source.coveo.com/2021/03/03/prometheus-memory/
3. https://www.robustperception.io/using-tsdb-analyze-to-investigate-churn-and-cardinality/
4. https://0xdc.me/blog/how-to-find-unused-prometheus-metrics-using-mimirtool/

For full command references:  
mimirtool: https://grafana.com/docs/mimir/latest/manage/tools/mimirtool/?pg=blog&plcmt=body-txt  
promtool: https://prometheus.io/docs/prometheus/latest/command-line/promtool/
